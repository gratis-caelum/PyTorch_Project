{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분할을 위한 폴더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "original_dataset_dir = '/Users/b._.chan/Documents/TABA_Project/Leaf_practice/dataset' # 원본 데이터셋이 위치한 경로 지정\n",
    "classes_list = [cls for cls in os.listdir(original_dataset_dir) if os.path.isdir(os.path.join(original_dataset_dir, cls))] \n",
    "# os.listdir() : 해당 경로 하위에 있는 모든 폴더의 목록을 가져오는 메소드\n",
    "\n",
    "base_dir = './splitted' # 나눈 데이터를 저장할 폴더 생성\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "# 분리 후에 각 데이터를 저장할 하위 폴더 train, val, test create\n",
    "train_dir = os.path.join(base_dir, 'train') \n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "# train, validation, test 폴더 하위에 각각 클래스 목록 폴더 생성\n",
    "for clss in classes_list:\n",
    "    os.mkdir(os.path.join(train_dir, clss))\n",
    "    os.mkdir(os.path.join(validation_dir, clss))    \n",
    "    os.mkdir(os.path.join(test_dir, clss))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분할과 클래스별 데이터 수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size( Strawberry___healthy ):  273\n",
      "Validation size( Strawberry___healthy ):  91\n",
      "Test size( Strawberry___healthy ):  91\n",
      "Train size( Grape___Black_rot ):  708\n",
      "Validation size( Grape___Black_rot ):  236\n",
      "Test size( Grape___Black_rot ):  236\n",
      "Train size( Potato___Early_blight ):  600\n",
      "Validation size( Potato___Early_blight ):  200\n",
      "Test size( Potato___Early_blight ):  200\n",
      "Train size( Cherry___Powdery_mildew ):  631\n",
      "Validation size( Cherry___Powdery_mildew ):  210\n",
      "Test size( Cherry___Powdery_mildew ):  210\n",
      "Train size( Tomato___Target_Spot ):  842\n",
      "Validation size( Tomato___Target_Spot ):  280\n",
      "Test size( Tomato___Target_Spot ):  280\n",
      "Train size( Peach___healthy ):  216\n",
      "Validation size( Peach___healthy ):  72\n",
      "Test size( Peach___healthy ):  72\n",
      "Train size( Potato___Late_blight ):  600\n",
      "Validation size( Potato___Late_blight ):  200\n",
      "Test size( Potato___Late_blight ):  200\n",
      "Train size( Tomato___Late_blight ):  1145\n",
      "Validation size( Tomato___Late_blight ):  381\n",
      "Test size( Tomato___Late_blight ):  381\n",
      "Train size( Tomato___Tomato_mosaic_virus ):  223\n",
      "Validation size( Tomato___Tomato_mosaic_virus ):  74\n",
      "Test size( Tomato___Tomato_mosaic_virus ):  74\n",
      "Train size( Pepper,_bell___healthy ):  886\n",
      "Validation size( Pepper,_bell___healthy ):  295\n",
      "Test size( Pepper,_bell___healthy ):  295\n",
      "Train size( Tomato___Leaf_Mold ):  571\n",
      "Validation size( Tomato___Leaf_Mold ):  190\n",
      "Test size( Tomato___Leaf_Mold ):  190\n",
      "Train size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  645\n",
      "Validation size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
      "Test size( Grape___Leaf_blight_(Isariopsis_Leaf_Spot) ):  215\n",
      "Train size( Apple___Cedar_apple_rust ):  165\n",
      "Validation size( Apple___Cedar_apple_rust ):  55\n",
      "Test size( Apple___Cedar_apple_rust ):  55\n",
      "Train size( Tomato___Bacterial_spot ):  1276\n",
      "Validation size( Tomato___Bacterial_spot ):  425\n",
      "Test size( Tomato___Bacterial_spot ):  425\n",
      "Train size( Grape___healthy ):  253\n",
      "Validation size( Grape___healthy ):  84\n",
      "Test size( Grape___healthy ):  84\n",
      "Train size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  307\n",
      "Validation size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
      "Test size( Corn___Cercospora_leaf_spot Gray_leaf_spot ):  102\n",
      "Train size( Tomato___Early_blight ):  600\n",
      "Validation size( Tomato___Early_blight ):  200\n",
      "Test size( Tomato___Early_blight ):  200\n",
      "Train size( Grape___Esca_(Black_Measles) ):  829\n",
      "Validation size( Grape___Esca_(Black_Measles) ):  276\n",
      "Test size( Grape___Esca_(Black_Measles) ):  276\n",
      "Train size( Tomato___healthy ):  954\n",
      "Validation size( Tomato___healthy ):  318\n",
      "Test size( Tomato___healthy ):  318\n",
      "Train size( Corn___Northern_Leaf_Blight ):  591\n",
      "Validation size( Corn___Northern_Leaf_Blight ):  197\n",
      "Test size( Corn___Northern_Leaf_Blight ):  197\n",
      "Train size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  3214\n",
      "Validation size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
      "Test size( Tomato___Tomato_Yellow_Leaf_Curl_Virus ):  1071\n",
      "Train size( Cherry___healthy ):  512\n",
      "Validation size( Cherry___healthy ):  170\n",
      "Test size( Cherry___healthy ):  170\n",
      "Train size( Apple___Apple_scab ):  378\n",
      "Validation size( Apple___Apple_scab ):  126\n",
      "Test size( Apple___Apple_scab ):  126\n",
      "Train size( Tomato___Spider_mites Two-spotted_spider_mite ):  1005\n",
      "Validation size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
      "Test size( Tomato___Spider_mites Two-spotted_spider_mite ):  335\n",
      "Train size( Corn___Common_rust ):  715\n",
      "Validation size( Corn___Common_rust ):  238\n",
      "Test size( Corn___Common_rust ):  238\n",
      "Train size( Peach___Bacterial_spot ):  1378\n",
      "Validation size( Peach___Bacterial_spot ):  459\n",
      "Test size( Peach___Bacterial_spot ):  459\n",
      "Train size( Pepper,_bell___Bacterial_spot ):  598\n",
      "Validation size( Pepper,_bell___Bacterial_spot ):  199\n",
      "Test size( Pepper,_bell___Bacterial_spot ):  199\n",
      "Train size( Tomato___Septoria_leaf_spot ):  1062\n",
      "Validation size( Tomato___Septoria_leaf_spot ):  354\n",
      "Test size( Tomato___Septoria_leaf_spot ):  354\n",
      "Train size( Corn___healthy ):  697\n",
      "Validation size( Corn___healthy ):  232\n",
      "Test size( Corn___healthy ):  232\n",
      "Train size( Apple___Black_rot ):  372\n",
      "Validation size( Apple___Black_rot ):  124\n",
      "Test size( Apple___Black_rot ):  124\n",
      "Train size( Apple___healthy ):  987\n",
      "Validation size( Apple___healthy ):  329\n",
      "Test size( Apple___healthy ):  329\n",
      "Train size( Strawberry___Leaf_scorch ):  665\n",
      "Validation size( Strawberry___Leaf_scorch ):  221\n",
      "Test size( Strawberry___Leaf_scorch ):  221\n",
      "Train size( Potato___healthy ):  91\n",
      "Validation size( Potato___healthy ):  30\n",
      "Test size( Potato___healthy ):  30\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# for문을 통해 모든 클래스에 대한 작업 반복\n",
    "for clss in classes_list:\n",
    "    path = os.path.join(original_dataset_dir, clss)\n",
    "    fnames = [fname for fname in os.listdir(path) if os.path.isfile(os.path.join(path, fname)) and not fname.startswith('.')] \n",
    "    # path 위치에 존재하는 모든 이미지 파일의 목록을 변수 fnames에 저장\n",
    "    \n",
    "    # Train, Validation, Test data의 비율을 지정. 이 프로젝트에서는 6:2:2 비율 지정\n",
    "    train_size = math.floor(len(fnames) * 0.6)\n",
    "    validation_size = math.floor(len(fnames) * 0.2)\n",
    "    test_size = math.floor(len(fnames) * 0.2)\n",
    "    \n",
    "    \n",
    "    train_fnames = fnames[:train_size]\n",
    "    print('Train size(', clss, '): ', len(train_fnames))\n",
    "    for fname in train_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(train_dir, clss), fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    validation_fnames = fnames[train_size:(validation_size + train_size)]\n",
    "    print('Validation size(', clss, '): ', len(validation_fnames))\n",
    "    for fname in validation_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(validation_dir, clss), fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    test_fnames = fnames[(train_size + validation_size):\n",
    "        (validation_size + train_size + test_size)]\n",
    "    \n",
    "    print('Test size(', clss, '): ', len(test_fnames))\n",
    "    for fname in test_fnames:\n",
    "        src = os.path.join(path, fname)\n",
    "        dst = os.path.join(os.path.join(test_dir, clss), fname)\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 학습을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "USE_MPS = torch.mps.is_available() # 현재 사용중인 환경에서 GPU를 사용할 수 있는지를 확인하는 Method (True/False)\n",
    "DEVICE = torch.device('mps' if USE_MPS else \"cpu\") # 사용하는 장비가 무엇인지를 저장하는 변수 (True : mps, False : cpu)\n",
    "\n",
    "BATCH_SIZE = 256 \n",
    "EPOCH = 30\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Compose : 이미지 데이터의 전처리, Augmentation(좌우 반전, 밝기 조절, 이미지 임의 확대) 등의 과정에서 사용되는 method,, \n",
    "# Augmentation 을 통해 이미지에 노이즈를 주어 더욱 강건한 모델을 만들 수 있음.\n",
    "transform_base = transforms.Compose([transforms.Resize((64, 64)), \n",
    "                                     transforms.ToTensor()])\n",
    "\n",
    "# ImageFolder method : 데이터셋을 불러오는 메소드 (이미지 데이터는 하나의 클래스가 하나의 폴더에 대응됨)\n",
    "train_dataset = ImageFolder(root='./splitted/train',\n",
    "                            transform=transform_base)\n",
    "val_dataset = ImageFolder(root='./splitted/val',\n",
    "                          transform=transform_base)\n",
    "\n",
    "# DataLoader는 불러온 이미지 데이터를 주어진 조건에 따라 Mini-batch 단위로 분리하는 역할 수행\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module): # 딥러닝 모델과 관련된 기본적인 함수를 포함하는 nn.Module 클래스를 상속하여 사용\n",
    "    def __init__(self): # 클래스 내부의 __init__ 함수에서는 모델에서 사용할 모든 Layer 정의\n",
    "        super(Net, self).__init__() # nn.Module 내에 있는 메서드를 상속받아 사용\n",
    "        \n",
    "        # 첫 번째 2d Convolutional Layer 정의 \n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2) # Kernel size =2, Stride = 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(4096, 512) # Flatten 이후에 사용될 첫 번째 Fully-connected Layer 정의\n",
    "        self.fc2 = nn.Linear(512, 33)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training) # training = self.training : 학습 모드일 때와 검증 모드일 때 각각 다르게 적용되기 위해 존재\n",
    "        # 학습 과정에서는 일부 노드를 랜덤하게 제외시키지만, 평가 과정에서는 모든 노드를 사용\n",
    "        x = self.conv2(x) # Convolution 연산을 진행한 후 Feature Map 생성\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.dropout(x, p=0.25, training=self.training) \n",
    "        \n",
    "        x = x.view(-1, 4096) # Flatten 연산 -> 1차원으로 펼침\n",
    "        x = self.fc1(x) # Flatten 된 1차원 Tensor를 fc1에 통과\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.fc2(x) # 마지막 Layer로 클래스의 개수에 해당하는 33개의 출력값을 가짐.\n",
    "        \n",
    "        output = F.log_softmax(x, dim=1) # 마지막 출력값에 softmax() 함수를 적용하여 데이터가 각 클래스에 속할 확률을 출력\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model_base = Net().to(DEVICE) # 정의한 CNN 모델 Net()의 새로운 객체 생성 후 모델을 현재 사용중인 장비에 할당\n",
    "optimizer = optim.Adam(model_base.parameters(), lr=0.001)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train() # 입력받는 모델을 학습 모드로 설정\n",
    "    # train_loader 에는 (data, target) 형태가 Mini-batch 단위로 묶여 있음\n",
    "    # train_loader에 enumerate() 함수를 적용했기 때문에 batch_idx, (data, target) 형태로 반복 가능한 객체가 생성되어\n",
    "    # for문 생성\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): \n",
    "        data, target = data.to(DEVICE), target.to(DEVICE) # data와 target 변수를 사용 중인 장비에 할당\n",
    "        optimizer.zero_grad() # 이전 Batch의 Gradient 값이 optimizer에 저장되어 있으므로 optimizer 초기화\n",
    "        output = model(data) # 데이터를 모델에 입력하여 Output 값 계산\n",
    "        loss = F.cross_entropy(output, target) # 모델에서 계산한 Output 값은 예측값과 Target 값 사이의 Loss 계산.. 분류 문제에 적합한 Cross Entropy Loss 사용\n",
    "        loss.backward() # 역전파 알고리즘 -> Loss 값을 바탕으로 Back Propagation을 통해 계산한 Gradient 값을 각 Parameter에 할당\n",
    "        optimizer.step() # Parameter를 Gradient 값을 이용해 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가를 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval() # 입력받는 모델을 평가 모드로 설정\n",
    "    test_loss = 0 # Mini-batch 별로 Loss를 합산해서 저장할 변수\n",
    "    correct = 0 # 올바르게 예측한 데이터 수를 세는 변수\n",
    "    \n",
    "    with torch.no_grad(): # 모델을 평가하는 단계에서는 모델의 Parameter를 업데이트하지 않아야 함.\n",
    "        # torch.no_grad() : 해당 부분을 실행하는 동안 모델의 Parameter 업데이트 중단\n",
    "        for data, target in test_loader: # for문을 통해 데이터와 대응하는 Label 값에 접근\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE) \n",
    "            output = model(data) # 데이터를 모델에 입력하여 output 값 계산\n",
    "            \n",
    "            # 모델에서 계산한 output 값인 예측값과 target 값 사이의 Loss 계산\n",
    "            # 성능 평가 과정에서도 Cross Entropy Loss 함수 사용\n",
    "            test_loss = F.cross_entropy(output,\n",
    "                                        target, reduction=\"sum\").item()\n",
    "            \n",
    "            # 모델에 입력된 Test Data가 33개의 클래스에 속할 확률값이 Output으로 출력되는데, 가장 높은 값을 가진 인덱스를 예측값을 저장\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            # target.view_as(pred)를 통해 target Tensor 구조를 pred Tensor와 같은 모양으로 정렬\n",
    "            # view_as() method : 적용 대상 Tensor를 메서드에 입력되는 Tensor 모양대로 재정렬하는 함수\n",
    "            # eq() method : 객체 간의 비교 연산자로 일치하면 1, 일치하지 않으면 0 반환\n",
    "    test_loss /= len(test_loader.dataset) # 모든 Mini-batch에서 합한 Loss 값을 Batch 수로 나누어 미니 배치마다 계산된 Loss 값 평균\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) # 모든 Mini-batch에서 합한 정확도 값을 Batch 수로 나누어 미니 배치마다 계산된 정확도 평균\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch 1 -------------------\n",
      "train_loss : 0.0106, Accuracy : 57.08%\n",
      "val_loss : 0.0097, val_acc : 56.83%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 2 -------------------\n",
      "train_loss : 0.0072, Accuracy : 68.44%\n",
      "val_loss : 0.0057, val_acc : 67.34%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 3 -------------------\n",
      "train_loss : 0.0068, Accuracy : 73.25%\n",
      "val_loss : 0.0060, val_acc : 71.86%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 4 -------------------\n",
      "train_loss : 0.0036, Accuracy : 83.18%\n",
      "val_loss : 0.0045, val_acc : 81.22%\n",
      "Completed in 1m 28s\n",
      "--------------- epoch 5 -------------------\n",
      "train_loss : 0.0044, Accuracy : 84.91%\n",
      "val_loss : 0.0052, val_acc : 82.73%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 6 -------------------\n",
      "train_loss : 0.0034, Accuracy : 84.79%\n",
      "val_loss : 0.0037, val_acc : 81.99%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 7 -------------------\n",
      "train_loss : 0.0027, Accuracy : 88.96%\n",
      "val_loss : 0.0022, val_acc : 86.11%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 8 -------------------\n",
      "train_loss : 0.0020, Accuracy : 89.71%\n",
      "val_loss : 0.0024, val_acc : 86.88%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 9 -------------------\n",
      "train_loss : 0.0019, Accuracy : 91.92%\n",
      "val_loss : 0.0017, val_acc : 88.66%\n",
      "Completed in 12m 21s\n",
      "--------------- epoch 10 -------------------\n",
      "train_loss : 0.0021, Accuracy : 92.40%\n",
      "val_loss : 0.0015, val_acc : 89.36%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 11 -------------------\n",
      "train_loss : 0.0017, Accuracy : 91.88%\n",
      "val_loss : 0.0031, val_acc : 88.56%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 12 -------------------\n",
      "train_loss : 0.0014, Accuracy : 91.98%\n",
      "val_loss : 0.0023, val_acc : 88.03%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 13 -------------------\n",
      "train_loss : 0.0013, Accuracy : 95.20%\n",
      "val_loss : 0.0015, val_acc : 91.10%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 14 -------------------\n",
      "train_loss : 0.0015, Accuracy : 94.06%\n",
      "val_loss : 0.0026, val_acc : 89.70%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 15 -------------------\n",
      "train_loss : 0.0011, Accuracy : 96.04%\n",
      "val_loss : 0.0009, val_acc : 92.00%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 16 -------------------\n",
      "train_loss : 0.0013, Accuracy : 94.80%\n",
      "val_loss : 0.0014, val_acc : 90.21%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 17 -------------------\n",
      "train_loss : 0.0015, Accuracy : 93.79%\n",
      "val_loss : 0.0020, val_acc : 89.29%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 18 -------------------\n",
      "train_loss : 0.0007, Accuracy : 97.32%\n",
      "val_loss : 0.0023, val_acc : 92.59%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 19 -------------------\n",
      "train_loss : 0.0009, Accuracy : 95.84%\n",
      "val_loss : 0.0016, val_acc : 90.77%\n",
      "Completed in 1m 29s\n",
      "--------------- epoch 20 -------------------\n",
      "train_loss : 0.0005, Accuracy : 97.44%\n",
      "val_loss : 0.0007, val_acc : 92.82%\n",
      "Completed in 1m 31s\n",
      "--------------- epoch 21 -------------------\n",
      "train_loss : 0.0008, Accuracy : 97.12%\n",
      "val_loss : 0.0013, val_acc : 91.99%\n",
      "Completed in 1m 32s\n",
      "--------------- epoch 22 -------------------\n",
      "train_loss : 0.0008, Accuracy : 97.68%\n",
      "val_loss : 0.0013, val_acc : 92.73%\n",
      "Completed in 1m 33s\n",
      "--------------- epoch 23 -------------------\n",
      "train_loss : 0.0004, Accuracy : 97.69%\n",
      "val_loss : 0.0014, val_acc : 92.14%\n",
      "Completed in 1m 33s\n",
      "--------------- epoch 24 -------------------\n",
      "train_loss : 0.0003, Accuracy : 98.50%\n",
      "val_loss : 0.0006, val_acc : 93.54%\n",
      "Completed in 1m 32s\n",
      "--------------- epoch 25 -------------------\n",
      "train_loss : 0.0004, Accuracy : 98.39%\n",
      "val_loss : 0.0009, val_acc : 93.09%\n",
      "Completed in 1m 30s\n",
      "--------------- epoch 26 -------------------\n",
      "train_loss : 0.0008, Accuracy : 96.45%\n",
      "val_loss : 0.0021, val_acc : 91.13%\n",
      "Completed in 1m 31s\n",
      "--------------- epoch 27 -------------------\n",
      "train_loss : 0.0004, Accuracy : 98.42%\n",
      "val_loss : 0.0033, val_acc : 93.08%\n",
      "Completed in 1m 32s\n",
      "--------------- epoch 28 -------------------\n",
      "train_loss : 0.0005, Accuracy : 98.89%\n",
      "val_loss : 0.0004, val_acc : 93.82%\n",
      "Completed in 1m 33s\n",
      "--------------- epoch 29 -------------------\n",
      "train_loss : 0.0003, Accuracy : 99.04%\n",
      "val_loss : 0.0007, val_acc : 93.93%\n",
      "Completed in 1m 35s\n",
      "--------------- epoch 30 -------------------\n",
      "train_loss : 0.0004, Accuracy : 98.14%\n",
      "val_loss : 0.0014, val_acc : 92.39%\n",
      "Completed in 1m 34s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "def train_baseline(model, train_loader, val_loader,\n",
    "                   optimizer, num_epochs=30):\n",
    "    best_acc = 0.0 # 정확도가 가장 높은 모델의 정확도를 저장하는 변수 선언\n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # 정확도가 가장 높은 모델을 저장할 변수 선언\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        since = time.time()     # 한 Epoch 당 소요되는 시간을 측정하기 위해 해당 Epoch을 시작할 때의 시각 저장\n",
    "        train(model, train_loader, optimizer) # 모델 학습\n",
    "        train_loss, train_acc = evaluate(model, train_loader) # 학습 Loss, 정확도 계산\n",
    "        val_loss, val_acc = evaluate(model, val_loader) # 검증 Loss, 정확도 계산\n",
    "        \n",
    "        if val_acc > best_acc: # 현재 Epoch의 검증 정확도가 최고 정확도보다 높다면 best_acc를 현재 Epoch의 검증 정확도로 업데이트\n",
    "            best_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict()) # 해당 Epoch의 모델을 best_model_wts에 저장\n",
    "            \n",
    "        time_elapsed = time.time() - since # 한 Epoch 당 소요된 시간 계산\n",
    "        print(f'--------------- epoch {epoch} -------------------')\n",
    "        \n",
    "        print('train_loss : {:.4f}, Accuracy : {:.2f}%'.format(train_loss, train_acc)) # 학습 Loss, 정확도 출력\n",
    "        print('val_loss : {:.4f}, val_acc : {:.2f}%'.format(val_loss, val_acc)) # 검증 Loss, 정확도 출력\n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60)) # 한 Epoch 당 소요된 시간 출력\n",
    "    \n",
    "    model.load_state_dict(best_model_wts) # 최종적으로 정확도가 가장 높은 모델을 불러온 뒤, 반환\n",
    "    return model\n",
    "\n",
    "base = train_baseline(model_base, train_loader, val_loader, optimizer, EPOCH) # Baseline 모델 학습\n",
    "\n",
    "torch.save(base, 'baseline.pt') # 학습이 완료된 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning을 위한 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([ # transforms.Compose() : 이미지 데이터의 전처리, Augmentation 등의 과정에서 사용\n",
    "        transforms.Resize([64, 64]), # transforms.Resize([64, 64]) : 이미지의 크기를 64 * 64로 조정\n",
    "        # Image Augmentation,, 이미지를 무작위로 좌우 반전.. 괄호 안에 Parameter p를 입력하여 반전되는 이미지의 비율을 설정할 수 있음 (Default : 0.5)\n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.RandomVerticalFlip(), # 이미지를 무작위로 상하 반전하는 것 (Default : 0.5)\n",
    "        transforms.RandomCrop(52), # 이미지의 일부를 랜덤으로 잘라 내어  52*52 사이즈로 변경\n",
    "        transforms.ToTensor(), # 이미지를 Tensor 형태로 변환하고 모든 숫자를 0에서 1 사이로 변경\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225]) # 이미지가 Tensor 형태로 전환된 이후에 정규화 시행 -> 정규화 위해서는 평균값과 표준편차 값 필요\n",
    "        # 첫 번째 대괄호[] 는 Red, Green, Blue 채널 값에서 정규화를 적용할 평균값을 의미\n",
    "        # 두 번째 대괄호[] 는 Red, Green, Blue 채널 값에서 정규화를 적용할 표준편차 값을 의미\n",
    "        # 이 데이터들은 Pre-trained Model 학습에 사용된 ImageNet 데이터 값\n",
    "        # 입력 데이터 정규화는 모델을 최적화하고, Local Mininum에 빠지는 것을 방지하는 데 도움이 됨.\n",
    "    ]),\n",
    "    \n",
    "    # 검증에 사용되는 데이터에는 학습에 적용했던 전처리에서 Augmentation에 해당하는 부분을 제외한 나머지 부분을 동일하게 적용\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize([64, 64]),\n",
    "        transforms.RandomCrop(52),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "data_dir = './splitted' # 학습 데이터와 검증 데이터를 불러올 폴더 경로 설정\n",
    "\n",
    "# ImageFolder 메서드는 데이터셋을 불러오는 Method\n",
    "# transform 옵션에는 데이터를 불러온 후 전처리 또는 Augmentation 방법 지정 -> transform_base로 옵션 지정\n",
    "# 훈련, 검증 과정에서 각각의 과정에 맞는 데이터를 편리하게 불러오고자 Dictionary 형태로 구성\n",
    "image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x),\n",
    "                                 transform=data_transforms[x]) for x in ['train', 'val']}\n",
    "\n",
    "# DataLoader는 불러온 이미지 데이터를 주어진 조건에 따라 Mini-batch 단위로 분리하는 역할\n",
    "# image_dataset을 이용하여 생성하고, Shuffle=True로 설정하여 Label 정보의 순서를 기억하는 것을 방지\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
    "                                              batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "               for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']} # 학습 데이터와 검증 데이터의 총 개수를 각각 저장\n",
    "\n",
    "class_names = image_datasets['train'].classes # 33개의 클래스 이름 목록을 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/TABA/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/TABA/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True) # pretrained = True : 미리 학습된 모델의 Parameter 값을 그대로 가져옴 (False : 모델의 구조만 -> Parameter : 랜덤)\n",
    "num_ftrs = resnet.fc.in_features # 이 프로젝트에서는 33개의 클래스로 분류해야 하기 때문에 마지막 Layer 출력 채널 수는 33개이어야 함.\n",
    "# ResNet50 모델은 다른 주제를 위해 설계되었기에 마지막 Layer의 출력 채널 수가 33개가 아님\n",
    "# 이 프로젝트의 주제에 맞추고자 모델의 마지막 FCL 대신 출력 채널의 수가 33개인 새로운 Layer 추가\n",
    "# ResNet50에서 마지막 Layer의 입력 채널 수를 저장,, in_features 는 해당 Layer의 입력 채널 수를 의미\n",
    "\n",
    "resnet.fc = nn.Linear(num_ftrs, 33) # 불러온 모델의 마지막 FCL을 새로운 Layer로 교체,,  입력 채널의 수는 기존 Layer와 동일하고 출력 채널 수는 목적에 맞게 설정\n",
    "resnet = resnet.to(DEVICE) # 모델을 현재 사용 중인 장비에 할당\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 모델을 학습할 때 사용하는 Loss 함수를 지정하는 변수\n",
    "\n",
    "# 이 모델에서는 설정한 일부 Layer의 Parameter만을 업데이트 해야 해서 filter() method와 lambda 표현식을 사용하여\n",
    "# requires_grad = True로 설정된 Layer의 Parameter에만 적용\n",
    "optimizer_ft = optim.Adam(filter(lambda p : p.requires_grad,\n",
    "                                 resnet.parameters()), lr=0.001)\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# StepLR() method는 Epoch에 따라 Learning Rate를 변경하는 역할을 함\n",
    "# step_size = 7, gamma = 0.1로 설정하면 7 Epoch 마다 0.1씩 곱해 Learning Rate를 감소시킨다는 의미\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft,\n",
    "                                       step_size=6, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained Model 일부 Layer Freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = 0 # 해당 Layer가 몇 번째 Layer인지 나타내는 변수\n",
    "for child in resnet.children(): # children method : 모델의 자식 모듈을 반복 가능한 객체로 반환하는 method\n",
    "    # resnet.children() method : 생성한 resnet 모델의 모든 Layer 정보를 담고 있음.\n",
    "    ct += 1 # for 문을 한 번 반복한 후에는 다음 Layer를 지칭하도록 변수 ct 값을 1만큼 증가\n",
    "    if ct < 6: # 미리 학습된 모델의 일부 Layer만 업데이트 하도록 설정하는 방법은 Parameter를 업데이트하지 않을 상위 Layer들의 requires_grad 값을 False로 지정\n",
    "        for param in child.parameters(): # ResNet50에 존재하는 10개의 Layer 중에서 1번부터 5번 Layer의 Parameter는 업데이트 되지 않도록 고정하고,\n",
    "            # 6번부터 10번 Layer의 Parameter는 학습 과정에서 업데이트하도록 설정\n",
    "            # child.parameters() : 각 Layer의 Parameter Tensor를 의미.. requries_grad : True\n",
    "            # requires_grad = False : Parameter가 업데이트되지 않도록 설정한다는 의미,, Layer의 번호가 6보다 작을 경우에는 Parameter가 업데이트 되지 않도록 설정\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning 모델 학습과 검증을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "def train_resnet(model, criterion, optimizer, schedular, num_epochs=25):\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict()) # 정확도가 가장 높은 모델을 저장할 변수\n",
    "    \n",
    "    best_acc = 0.0 # 정확도가 가장 높은 모델의 정확도를 저장하는 변수 선언\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('----------------- epoch {} -------------'.format(epoch + 1)) # 현재 진행중은 Epoch\n",
    "        since = time.time() # 한 Epoch 당 소요되는 시간을 측정하기 위해 시작 시각 저장\n",
    "        \n",
    "        for phase in ['train', 'val']: # 한 Epoch은 각각 학습 단계와 검증 단계를 가지고, 한 Epoch 마다 학습 모드와 검증 모드를 각각 실행\n",
    "            if phase == 'train': # 상황에 적합하게 모델을 학습 모드로 설정\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval() # 상황에 적합하게 모델을 검증 모드로 설정\n",
    "            \n",
    "            \n",
    "            running_loss = 0.0 # 모든 데이터의 Loss를 합산해서 저장할 변수\n",
    "            running_corrects = 0 # 올바르게 예측한 경우의 수를 세는 변수\n",
    "            \n",
    "            for inputs, labels in dataloaders[phase]: # 모델의 현재 모드에 해당하는 DataLoader에서 데이터 입력\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE) # 데이터와 해당하는 Label 값을 현재 사용중인 장비에 할당\n",
    "                \n",
    "                optimizer.zero_grad() # Gradient 초기화\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'): # 학습 단게에서만 모델 Gradient를 업데이트하고, 검증 단게에서는\n",
    "                    # 업데이트 하지 않아야 하므로 set_grad_enabled() method를 사용하여 phase가 train일 경우에만 업데이트하도록 설정\n",
    "                    outputs = model(inputs) # 데이터를 모델에 입력하여 Output 값 계산\n",
    "                    _, preds = torch.max(outputs, 1) # 모델에 입력된 test 데이터가 33개의 클래스에 속할 각각의 확률값이\n",
    "                    # Output으로 출력되고 그 중 가장 높은 값을 가진 인덱스를 예측값으로 저장\n",
    "                    loss = criterion(outputs, labels) \n",
    "                    \n",
    "                    # 모델이 현재 학습 모드인 경우 앞에서 계산한 Loss 값을 바탕으로 Back Propagation을 통해 계산한 \n",
    "                    # Gradient 값을 각 Parameter에 할당하고, 모델의 Parameter를 Update\n",
    "                    if phase == 'train': \n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                \n",
    "                # 모든 데이터 Loss를 합산해서 저장하고자 하나의 Mini-batch에 대해 계산된 Loss 값에 데이터의 수를 곱해 합산\n",
    "                # 이 때 inputs.size(0)은 DataLoader에서 전달되는 Mini-batch의 데이터 수를 의미하는 것으로, Batch_size        \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data) # 앞에서 모델을 통해 예측한 값과 Target이 같으면 running_corrects를 1만큼 증가\n",
    "            if phase == 'train': # 7 Epoch 마다 Learning Rate를 다르게 조정하는 Scheduler와 관련된 부분,, 한 Epoch당 1번 모델이 현재 학습 단계일 경우에만 실행\n",
    "                schedular.step()\n",
    "                # Scheduler에 의해 Learning Rate가 조정되는 것을 직접 확인하기 위한 부분\n",
    "                # optimizer_ft.param_groups의 원소는 학습 과정에서의 Parameter를 저장하고 있는 dictionary\n",
    "                # 이 중 Learning Rate에 해당하는 Key인 \"lr\"를 이용하여 각 Epoch의 Learning Rate를 불러옴\n",
    "                l_r = [x['lr'] for x in optimizer_ft.param_groups] \n",
    "                print('learning rate : ' , l_r)\n",
    "        \n",
    "            # 해당 Epoch의 Loss를 계산하기 위해 running_loss를 미리 계산해 둔 dataset_size로 나눔\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            # 해당 Epoch의 정확도를 계산하기 위해 running_corrects를 미리 계산해 둔 dataset_size로 나눔\n",
    "            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n",
    "            \n",
    "            # 해당 Epoch과 현재 모델의 단계, Loss 값, 정확도를 출력\n",
    "            print('{} loss : {:.4f} Acc : {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "            \n",
    "            # 검증 단게에서 현재 Epoch의 정확도가 최고 정확도보다 높다면 \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc # best_acc를 현재 Epoch의 정확도로 업데이트\n",
    "                best_model_wts = copy.deepcopy(model.state_dict()) # 해당 Epoch의 모델을 best_model_wts에 저장\n",
    "                \n",
    "        time_elasped = time.time() - since\n",
    "        \n",
    "        print('completed in {:.0f}m {:0f}s'.format(time_elasped // 60, time_elasped % 60))\n",
    "    print('Best val Acc : {:.4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts) # 정확도가 가장 높은 모델을 불러온 후 반환\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- epoch 1 -------------\n",
      "learning rate :  [0.001]\n",
      "train loss : 0.2196 Acc : 0.9279\n",
      "val loss : 0.2219 Acc : 0.9313\n",
      "completed in 1m 52.473299s\n",
      "----------------- epoch 2 -------------\n",
      "learning rate :  [0.001]\n",
      "train loss : 0.1728 Acc : 0.9430\n",
      "val loss : 0.1982 Acc : 0.9345\n",
      "completed in 3m 1.150282s\n",
      "----------------- epoch 3 -------------\n",
      "learning rate :  [0.001]\n",
      "train loss : 0.1399 Acc : 0.9524\n",
      "val loss : 0.1707 Acc : 0.9456\n",
      "completed in 3m 6.154328s\n",
      "----------------- epoch 4 -------------\n",
      "learning rate :  [0.001]\n",
      "train loss : 0.1099 Acc : 0.9633\n",
      "val loss : 0.1364 Acc : 0.9569\n",
      "completed in 2m 34.458076s\n",
      "----------------- epoch 5 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0961 Acc : 0.9685\n",
      "val loss : 0.1264 Acc : 0.9591\n",
      "completed in 2m 39.678178s\n",
      "----------------- epoch 6 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0494 Acc : 0.9840\n",
      "val loss : 0.0524 Acc : 0.9834\n",
      "completed in 2m 56.966598s\n",
      "----------------- epoch 7 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0323 Acc : 0.9897\n",
      "val loss : 0.0457 Acc : 0.9855\n",
      "completed in 2m 56.048617s\n",
      "----------------- epoch 8 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0270 Acc : 0.9910\n",
      "val loss : 0.0481 Acc : 0.9847\n",
      "completed in 2m 55.083387s\n",
      "----------------- epoch 9 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0230 Acc : 0.9925\n",
      "val loss : 0.0412 Acc : 0.9875\n",
      "completed in 2m 52.068085s\n",
      "----------------- epoch 10 -------------\n",
      "learning rate :  [0.0001]\n",
      "train loss : 0.0212 Acc : 0.9931\n",
      "val loss : 0.0399 Acc : 0.9869\n",
      "completed in 2m 50.854803s\n",
      "----------------- epoch 11 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0175 Acc : 0.9949\n",
      "val loss : 0.0419 Acc : 0.9874\n",
      "completed in 2m 54.171609s\n",
      "----------------- epoch 12 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0177 Acc : 0.9947\n",
      "val loss : 0.0359 Acc : 0.9900\n",
      "completed in 2m 42.929418s\n",
      "----------------- epoch 13 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0146 Acc : 0.9957\n",
      "val loss : 0.0358 Acc : 0.9880\n",
      "completed in 2m 49.598343s\n",
      "----------------- epoch 14 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0156 Acc : 0.9950\n",
      "val loss : 0.0386 Acc : 0.9885\n",
      "completed in 2m 33.546937s\n",
      "----------------- epoch 15 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0153 Acc : 0.9952\n",
      "val loss : 0.0400 Acc : 0.9877\n",
      "completed in 2m 54.053980s\n",
      "----------------- epoch 16 -------------\n",
      "learning rate :  [1e-05]\n",
      "train loss : 0.0151 Acc : 0.9952\n",
      "val loss : 0.0409 Acc : 0.9877\n",
      "completed in 2m 41.572200s\n",
      "----------------- epoch 17 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0142 Acc : 0.9954\n",
      "val loss : 0.0393 Acc : 0.9881\n",
      "completed in 2m 15.016124s\n",
      "----------------- epoch 18 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0137 Acc : 0.9956\n",
      "val loss : 0.0362 Acc : 0.9894\n",
      "completed in 1m 49.917748s\n",
      "----------------- epoch 19 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0132 Acc : 0.9960\n",
      "val loss : 0.0361 Acc : 0.9904\n",
      "completed in 10m 21.322080s\n",
      "----------------- epoch 20 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0131 Acc : 0.9960\n",
      "val loss : 0.0359 Acc : 0.9886\n",
      "completed in 2m 12.530556s\n",
      "----------------- epoch 21 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0158 Acc : 0.9950\n",
      "val loss : 0.0385 Acc : 0.9882\n",
      "completed in 4m 56.037914s\n",
      "----------------- epoch 22 -------------\n",
      "learning rate :  [1.0000000000000002e-06]\n",
      "train loss : 0.0138 Acc : 0.9960\n",
      "val loss : 0.0363 Acc : 0.9892\n",
      "completed in 2m 52.878261s\n",
      "----------------- epoch 23 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0139 Acc : 0.9960\n",
      "val loss : 0.0365 Acc : 0.9896\n",
      "completed in 3m 21.342916s\n",
      "----------------- epoch 24 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0140 Acc : 0.9957\n",
      "val loss : 0.0355 Acc : 0.9892\n",
      "completed in 2m 55.046968s\n",
      "----------------- epoch 25 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0148 Acc : 0.9951\n",
      "val loss : 0.0366 Acc : 0.9895\n",
      "completed in 3m 3.773745s\n",
      "----------------- epoch 26 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0140 Acc : 0.9959\n",
      "val loss : 0.0380 Acc : 0.9890\n",
      "completed in 2m 49.073272s\n",
      "----------------- epoch 27 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0145 Acc : 0.9950\n",
      "val loss : 0.0376 Acc : 0.9884\n",
      "completed in 2m 5.996309s\n",
      "----------------- epoch 28 -------------\n",
      "learning rate :  [1.0000000000000002e-07]\n",
      "train loss : 0.0132 Acc : 0.9962\n",
      "val loss : 0.0392 Acc : 0.9884\n",
      "completed in 2m 7.176135s\n",
      "----------------- epoch 29 -------------\n",
      "learning rate :  [1.0000000000000004e-08]\n",
      "train loss : 0.0130 Acc : 0.9958\n",
      "val loss : 0.0370 Acc : 0.9876\n",
      "completed in 2m 15.668153s\n",
      "----------------- epoch 30 -------------\n",
      "learning rate :  [1.0000000000000004e-08]\n",
      "train loss : 0.0138 Acc : 0.9957\n",
      "val loss : 0.0346 Acc : 0.9891\n",
      "completed in 2m 4.478098s\n",
      "Best val Acc : 0.9904\n"
     ]
    }
   ],
   "source": [
    "model_resnet50 = train_resnet(resnet, criterion, optimizer_ft,\n",
    "                              exp_lr_scheduler, num_epochs=EPOCH)\n",
    "\n",
    "torch.save(model_resnet50, 'resnet50.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 평가를 위한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이스라인 모델의 성능 평가를 위해 사용할 테스트 데이터의 DataLoader 생성\n",
    "# 모델을 학습시킬 때 사용한 학습, 검증 데이터와 동일한 방법으로 전처리 수행, 배치 사이즈 동일\n",
    "transform_base = transforms.Compose([transforms.Resize([64, 64]),\n",
    "                                     transforms.ToTensor()])\n",
    "test_base = ImageFolder(root='./splitted/test',\n",
    "                        transform=transform_base)\n",
    "\n",
    "test_loader_base = torch.utils.data.DataLoader(test_base,\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               shuffle=True,\n",
    "                                               num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning Model evaluation을 위한 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer Learning model 성능 평가를 위해 사용할 테스트 데이터의 DataLoader 생성\n",
    "# Transfer Learning model의 경우에도 마찬가지로 모델을 학습시킬 때 사용한 학습, 검증 데이터와 동일한 방법으로 전처리 수행\n",
    "# 배치 사이즈도 동일하게 설정\n",
    "\n",
    "transform_resNet = transforms.Compose([\n",
    "    transforms.Resize([64, 64]),\n",
    "    transforms.RandomCrop(52),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_resNet = ImageFolder(root='./splitted/test',\n",
    "                          transform=transform_resNet)\n",
    "\n",
    "test_loader_resNet = torch.utils.data.DataLoader(dataset=test_resNet,\n",
    "                                                 batch_size=BATCH_SIZE,\n",
    "                                                 shuffle=True,\n",
    "                                                 num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이스라인 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/dngzdyds4h36v9fcy0qzhlj40000gn/T/ipykernel_81044/1274393065.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  baseline = torch.load('baseline.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline test acc:  94.07935911878833\n"
     ]
    }
   ],
   "source": [
    "# 저장했던 베이스라인 모델 불러옴\n",
    "baseline = torch.load('baseline.pt')\n",
    "baseline.eval() # 모델을 평가 모드로 설정\n",
    "# 앞서 정의한 evaluate 함수를 이용하여 테스트 데이터에 대한 정확도 측정\n",
    "test_loss, test_accuracy = evaluate(baseline, test_loader=test_loader_base)\n",
    "\n",
    "print('baseline test acc: ', test_accuracy) # 평가 정확도 출력\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t6/dngzdyds4h36v9fcy0qzhlj40000gn/T/ipykernel_81044/89219646.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50 = torch.load('resnet50.pt')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet test acc : 98.86093378395293\n"
     ]
    }
   ],
   "source": [
    "# 저장된 Transfer Learning model 불러오기\n",
    "resnet50 = torch.load('resnet50.pt')\n",
    "resnet50.eval() # 모델을 평가 모드로 설정\n",
    "# 앞서 정의한 evaluate 함수를 이용하여 테스트 데이터에 대한 정확도 측정\n",
    "test_loss, test_accuracy = evaluate(model=resnet50, test_loader=test_loader_resNet)\n",
    "\n",
    "# 평가 정확도 출력\n",
    "print(f\"ResNet test acc : {test_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TABA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
